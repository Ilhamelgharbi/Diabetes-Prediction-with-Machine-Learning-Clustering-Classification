{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e149ac",
   "metadata": {},
   "source": [
    "# Classification supervisée basée sur les clusters\n",
    "\n",
    "**Objectif :** Développer un modèle de classification supervisée pour prédire les phénotypes métaboliques du diabète en utilisant les résultats du clustering K-means.\n",
    "\n",
    "---\n",
    "\n",
    "## Vue d'ensemble du pipeline\n",
    "\n",
    "Cette analyse comprend les étapes suivantes :\n",
    "1. **Importation des bibliothèques** et configuration\n",
    "2. **Chargement et préparation des données**\n",
    "3. **Preprocessing** (standardisation et équilibrage des classes)\n",
    "4. **Initialisation des modèles** de machine learning\n",
    "5. **Entraînement et évaluation initiale**\n",
    "6. **Validation croisée** pour robustesse\n",
    "7. **Optimisation des hyperparamètres** avec GridSearchCV\n",
    "8. **Évaluation finale** et sélection du meilleur modèle\n",
    "9. **Sauvegarde** du modèle optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ebe74",
   "metadata": {},
   "source": [
    "## 1. Importation des bibliothèques\n",
    "\n",
    "Importation de toutes les bibliothèques nécessaires pour l'analyse de classification supervisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6633c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06601fa3",
   "metadata": {},
   "source": [
    "## 2. Chargement et préparation des données\n",
    "\n",
    "Chargement des datasets issus du clustering et définition des variables explicatives et de la variable cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "270ad0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chargement et préparation des données ---\n",
    "\n",
    "df_cluster_final = pd.read_csv('../data/df_cluster_final.csv')\n",
    "df_cluster = pd.read_csv('../data/df_cluster.csv')\n",
    "\n",
    "# Cible\n",
    "y = df_cluster_final['cluster']\n",
    "\n",
    "# Variables sélectionnées\n",
    "X = df_cluster[['Glucose', 'BMI', 'Age', 'DiabetesPedigreeFunction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc93380",
   "metadata": {},
   "source": [
    "## 3. Preprocessing des données\n",
    "\n",
    "### 3.1 Division train/test et standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d576f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcee71",
   "metadata": {},
   "source": [
    "### 3.2 Équilibrage des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb04d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train count: cluster\n",
      "0    323\n",
      "1    244\n",
      "Name: count, dtype: int64\n",
      "y_train count: cluster\n",
      "0    323\n",
      "1    323\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sur-échantillonnage (pour équilibrer les classes)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "print(\"y_train count:\", y_train.value_counts())\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "print(\"y_train count:\", y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805f094",
   "metadata": {},
   "source": [
    "## 4. Initialisation des modèles\n",
    "\n",
    "Configuration des algorithmes de machine learning à comparer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7710d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialisation des modèles ---\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Régression Logistique\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb25d2e7",
   "metadata": {},
   "source": [
    "## 5. Entraînement et évaluation initiale\n",
    "\n",
    "Première évaluation des modèles avec les paramètres par défaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6200dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Entraînement initial des modèles ===\n",
      "\n",
      "Modèle : Random Forest\n",
      "Accuracy    : 0.9577\n",
      "Precision   : 0.9588\n",
      "Recall      : 0.9562\n",
      "F1-score    : 0.9573\n",
      "Matrice de confusion :\n",
      "[[75  2]\n",
      " [ 4 61]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        77\n",
      "           1       0.97      0.94      0.95        65\n",
      "\n",
      "    accuracy                           0.96       142\n",
      "   macro avg       0.96      0.96      0.96       142\n",
      "weighted avg       0.96      0.96      0.96       142\n",
      "\n",
      "\n",
      "Modèle : SVM\n",
      "Accuracy    : 0.9930\n",
      "Precision   : 0.9924\n",
      "Recall      : 0.9935\n",
      "F1-score    : 0.9929\n",
      "Matrice de confusion :\n",
      "[[76  1]\n",
      " [ 0 65]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        77\n",
      "           1       0.98      1.00      0.99        65\n",
      "\n",
      "    accuracy                           0.99       142\n",
      "   macro avg       0.99      0.99      0.99       142\n",
      "weighted avg       0.99      0.99      0.99       142\n",
      "\n",
      "\n",
      "Modèle : Random Forest\n",
      "Accuracy    : 0.9577\n",
      "Precision   : 0.9588\n",
      "Recall      : 0.9562\n",
      "F1-score    : 0.9573\n",
      "Matrice de confusion :\n",
      "[[75  2]\n",
      " [ 4 61]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        77\n",
      "           1       0.97      0.94      0.95        65\n",
      "\n",
      "    accuracy                           0.96       142\n",
      "   macro avg       0.96      0.96      0.96       142\n",
      "weighted avg       0.96      0.96      0.96       142\n",
      "\n",
      "\n",
      "Modèle : SVM\n",
      "Accuracy    : 0.9930\n",
      "Precision   : 0.9924\n",
      "Recall      : 0.9935\n",
      "F1-score    : 0.9929\n",
      "Matrice de confusion :\n",
      "[[76  1]\n",
      " [ 0 65]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        77\n",
      "           1       0.98      1.00      0.99        65\n",
      "\n",
      "    accuracy                           0.99       142\n",
      "   macro avg       0.99      0.99      0.99       142\n",
      "weighted avg       0.99      0.99      0.99       142\n",
      "\n",
      "\n",
      "Modèle : Gradient Boosting\n",
      "Accuracy    : 0.9648\n",
      "Precision   : 0.9669\n",
      "Recall      : 0.9627\n",
      "F1-score    : 0.9644\n",
      "Matrice de confusion :\n",
      "[[76  1]\n",
      " [ 4 61]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        77\n",
      "           1       0.98      0.94      0.96        65\n",
      "\n",
      "    accuracy                           0.96       142\n",
      "   macro avg       0.97      0.96      0.96       142\n",
      "weighted avg       0.97      0.96      0.96       142\n",
      "\n",
      "\n",
      "Modèle : Régression Logistique\n",
      "Accuracy    : 1.0000\n",
      "Precision   : 1.0000\n",
      "Recall      : 1.0000\n",
      "F1-score    : 1.0000\n",
      "Matrice de confusion :\n",
      "[[77  0]\n",
      " [ 0 65]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        77\n",
      "           1       1.00      1.00      1.00        65\n",
      "\n",
      "    accuracy                           1.00       142\n",
      "   macro avg       1.00      1.00      1.00       142\n",
      "weighted avg       1.00      1.00      1.00       142\n",
      "\n",
      "\n",
      "Modèle : Gradient Boosting\n",
      "Accuracy    : 0.9648\n",
      "Precision   : 0.9669\n",
      "Recall      : 0.9627\n",
      "F1-score    : 0.9644\n",
      "Matrice de confusion :\n",
      "[[76  1]\n",
      " [ 4 61]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        77\n",
      "           1       0.98      0.94      0.96        65\n",
      "\n",
      "    accuracy                           0.96       142\n",
      "   macro avg       0.97      0.96      0.96       142\n",
      "weighted avg       0.97      0.96      0.96       142\n",
      "\n",
      "\n",
      "Modèle : Régression Logistique\n",
      "Accuracy    : 1.0000\n",
      "Precision   : 1.0000\n",
      "Recall      : 1.0000\n",
      "F1-score    : 1.0000\n",
      "Matrice de confusion :\n",
      "[[77  0]\n",
      " [ 0 65]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        77\n",
      "           1       1.00      1.00      1.00        65\n",
      "\n",
      "    accuracy                           1.00       142\n",
      "   macro avg       1.00      1.00      1.00       142\n",
      "weighted avg       1.00      1.00      1.00       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Entraînement et évaluation initiale ---\n",
    "print(\"=== Entraînement initial des modèles ===\")\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\nModèle : {name}\")\n",
    "    print(f\"Accuracy    : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision   : {precision_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "    print(f\"Recall      : {recall_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "    print(f\"F1-score    : {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "    print(\"Matrice de confusion :\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nRapport complet :\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4775774",
   "metadata": {},
   "source": [
    "## 6. Validation croisée\n",
    "\n",
    "Évaluation de la robustesse des modèles avec validation croisée 5-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6539b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Validation croisée 5-fold avec plusieurs métriques ===\n",
      "\n",
      "Random Forest :\n",
      "  accuracy moyen = 0.9629\n",
      "  precision_macro moyen = 0.9637\n",
      "  recall_macro moyen = 0.9628\n",
      "  f1_macro moyen = 0.9628\n",
      "\n",
      "Random Forest :\n",
      "  accuracy moyen = 0.9629\n",
      "  precision_macro moyen = 0.9637\n",
      "  recall_macro moyen = 0.9628\n",
      "  f1_macro moyen = 0.9628\n",
      "\n",
      "SVM :\n",
      "  accuracy moyen = 0.9938\n",
      "  precision_macro moyen = 0.9940\n",
      "  recall_macro moyen = 0.9938\n",
      "  f1_macro moyen = 0.9938\n",
      "\n",
      "SVM :\n",
      "  accuracy moyen = 0.9938\n",
      "  precision_macro moyen = 0.9940\n",
      "  recall_macro moyen = 0.9938\n",
      "  f1_macro moyen = 0.9938\n",
      "\n",
      "Gradient Boosting :\n",
      "  accuracy moyen = 0.9675\n",
      "  precision_macro moyen = 0.9678\n",
      "  recall_macro moyen = 0.9674\n",
      "  f1_macro moyen = 0.9675\n",
      "\n",
      "Régression Logistique :\n",
      "  accuracy moyen = 0.9954\n",
      "  precision_macro moyen = 0.9954\n",
      "  recall_macro moyen = 0.9954\n",
      "  f1_macro moyen = 0.9954\n",
      "\n",
      "Gradient Boosting :\n",
      "  accuracy moyen = 0.9675\n",
      "  precision_macro moyen = 0.9678\n",
      "  recall_macro moyen = 0.9674\n",
      "  f1_macro moyen = 0.9675\n",
      "\n",
      "Régression Logistique :\n",
      "  accuracy moyen = 0.9954\n",
      "  precision_macro moyen = 0.9954\n",
      "  recall_macro moyen = 0.9954\n",
      "  f1_macro moyen = 0.9954\n"
     ]
    }
   ],
   "source": [
    "# --- Validation croisée 5-fold avec plusieurs métriques ---\n",
    "print(\"\\n=== Validation croisée 5-fold avec plusieurs métriques ===\")\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_validate(model, X_train_resampled, y_train_resampled, cv=5, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "    cv_results[name] = {metric: scores['test_'+metric].mean() for metric in scoring}\n",
    "    print(f\"\\n{name} :\")\n",
    "    for metric in scoring:\n",
    "        print(f\"  {metric} moyen = {cv_results[name][metric]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84475a1a",
   "metadata": {},
   "source": [
    "## 7. Optimisation des hyperparamètres\n",
    "\n",
    "### 7.1 Définition des grilles d'hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bd2e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grilles d'hyperparamètres pour GridSearchCV ---\n",
    "params = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [10, 20, None]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    'Régression Logistique': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb0b007",
   "metadata": {},
   "source": [
    "### 7.2 Fonction d'optimisation et exécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb7433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimisation de Random Forest...\n",
      "Meilleurs paramètres pour Random Forest : {'max_depth': 10, 'n_estimators': 50}\n",
      "Meilleur score f1_macro : 0.9690\n",
      "\n",
      "Optimisation de SVM...\n",
      "Meilleurs paramètres pour SVM : {'C': 10, 'kernel': 'linear'}\n",
      "Meilleur score f1_macro : 0.9984\n",
      "\n",
      "Optimisation de Gradient Boosting...\n",
      "Meilleurs paramètres pour Random Forest : {'max_depth': 10, 'n_estimators': 50}\n",
      "Meilleur score f1_macro : 0.9690\n",
      "\n",
      "Optimisation de SVM...\n",
      "Meilleurs paramètres pour SVM : {'C': 10, 'kernel': 'linear'}\n",
      "Meilleur score f1_macro : 0.9984\n",
      "\n",
      "Optimisation de Gradient Boosting...\n",
      "Meilleurs paramètres pour Gradient Boosting : {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Meilleur score f1_macro : 0.9721\n",
      "\n",
      "Optimisation de Régression Logistique...\n",
      "Meilleurs paramètres pour Régression Logistique : {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Meilleur score f1_macro : 0.9984\n",
      "Meilleurs paramètres pour Gradient Boosting : {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Meilleur score f1_macro : 0.9721\n",
      "\n",
      "Optimisation de Régression Logistique...\n",
      "Meilleurs paramètres pour Régression Logistique : {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Meilleur score f1_macro : 0.9984\n"
     ]
    }
   ],
   "source": [
    "# --- Fonction d'optimisation avec GridSearchCV ---\n",
    "def tune_models(X, y, models, params, cv=5, scoring='f1_macro'):\n",
    "    best_models = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nOptimisation de {name}...\")\n",
    "        grid = GridSearchCV(model, params[name], cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        grid.fit(X, y)\n",
    "        print(f\"Meilleurs paramètres pour {name} : {grid.best_params_}\")\n",
    "        print(f\"Meilleur score {scoring} : {grid.best_score_:.4f}\")\n",
    "        best_models[name] = grid.best_estimator_\n",
    "    return best_models\n",
    "\n",
    "best_models = tune_models(X_train_resampled, y_train_resampled, models, params, cv=5, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d6bad0",
   "metadata": {},
   "source": [
    "## 8. Évaluation finale des modèles optimisés\n",
    "\n",
    "Évaluation complète des modèles optimisés sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46ad1425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Évaluation des modèles optimisés sur le test set ===\n",
      "\n",
      "Modèle : Random Forest\n",
      "Accuracy    : 0.9577\n",
      "Precision   : 0.9574\n",
      "Recall      : 0.9574\n",
      "F1-score    : 0.9574\n",
      "Matrice de confusion :\n",
      "[[74  3]\n",
      " [ 3 62]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        77\n",
      "           1       0.95      0.95      0.95        65\n",
      "\n",
      "    accuracy                           0.96       142\n",
      "   macro avg       0.96      0.96      0.96       142\n",
      "weighted avg       0.96      0.96      0.96       142\n",
      "\n",
      "\n",
      "Modèle : SVM\n",
      "Accuracy    : 0.9930\n",
      "Precision   : 0.9924\n",
      "Recall      : 0.9935\n",
      "F1-score    : 0.9929\n",
      "Matrice de confusion :\n",
      "[[76  1]\n",
      " [ 0 65]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        77\n",
      "           1       0.98      1.00      0.99        65\n",
      "\n",
      "    accuracy                           0.99       142\n",
      "   macro avg       0.99      0.99      0.99       142\n",
      "weighted avg       0.99      0.99      0.99       142\n",
      "\n",
      "\n",
      "Modèle : Gradient Boosting\n",
      "Accuracy    : 0.9437\n",
      "Precision   : 0.9494\n",
      "Recall      : 0.9397\n",
      "F1-score    : 0.9427\n",
      "Matrice de confusion :\n",
      "[[76  1]\n",
      " [ 7 58]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        77\n",
      "           1       0.98      0.89      0.94        65\n",
      "\n",
      "    accuracy                           0.94       142\n",
      "   macro avg       0.95      0.94      0.94       142\n",
      "weighted avg       0.95      0.94      0.94       142\n",
      "\n",
      "\n",
      "Modèle : Régression Logistique\n",
      "Accuracy    : 0.9930\n",
      "Precision   : 0.9924\n",
      "Recall      : 0.9935\n",
      "F1-score    : 0.9929\n",
      "Matrice de confusion :\n",
      "[[76  1]\n",
      " [ 0 65]]\n",
      "\n",
      "Rapport complet :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        77\n",
      "           1       0.98      1.00      0.99        65\n",
      "\n",
      "    accuracy                           0.99       142\n",
      "   macro avg       0.99      0.99      0.99       142\n",
      "weighted avg       0.99      0.99      0.99       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Ré-évaluation des modèles optimisés sur le test set ---\n",
    "print(\"\\n=== Évaluation des modèles optimisés sur le test set ===\")\n",
    "final_scores = {}\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro')\n",
    "    rec = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    final_scores[name] = f1\n",
    "\n",
    "    print(f\"\\nModèle : {name}\")\n",
    "    print(f\"Accuracy    : {acc:.4f}\")\n",
    "    print(f\"Precision   : {prec:.4f}\")\n",
    "    print(f\"Recall      : {rec:.4f}\")\n",
    "    print(f\"F1-score    : {f1:.4f}\")\n",
    "    print(\"Matrice de confusion :\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nRapport complet :\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a03c31",
   "metadata": {},
   "source": [
    "## 9. Sélection et sauvegarde du meilleur modèle\n",
    "\n",
    "Identification du modèle avec les meilleures performances et sauvegarde pour utilisation future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5313748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Meilleur modèle final : SVM avec un F1-score macro de 0.9929\n",
      "Modèle sauvegardé dans '../models/model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# --- Sélection et sauvegarde du meilleur modèle (meilleur F1 macro) ---\n",
    "best_model_name = max(final_scores, key=final_scores.get)\n",
    "best_model = best_models[best_model_name]\n",
    "print(f\"\\n🏆 Meilleur modèle final : {best_model_name} avec un F1-score macro de {final_scores[best_model_name]:.4f}\")\n",
    "\n",
    "joblib.dump(best_model, '../models/model.pkl')\n",
    "print(\"Modèle sauvegardé dans '../models/model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f1175aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler sauvegardé dans '../models/scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du scaler pour utilisation dans l'application Streamlit\n",
    "import joblib\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print(\"Scaler sauvegardé dans '../models/scaler.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
